			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

Sean Hogan <seanhogan@uchicago.edu>
Charles Cary <cioc@uchicago.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

thread.c
--------

/* The list of sleeping threads */
static struct list wait_list;

thread.h
--------

/* Used for allowing a thread to be in the wait_list */
struct list_elem waitelem;

/* A semaphore that a thread uses to put itself to sleep */
struct semaphore timer_semaphore;

/* When a thread sleeps, it should wake up at this time relative to the kernel starting. */
int64_t wakeup_time;

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

We tell the current running thread to sleep for TICKS ticks. This just changes the running thread's wakeup time to be the current time + TICKS. The running thread is inserted into "wait_list" which is sorted in ascending order by wakeup time. Then, the thread is put to sleep and blocks, via sema_init and sema_down.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

We added a call to "thread.c::thread_wake_routine" , which just iterates through the sleeping threads and sees if any of them need to be woken up. This is fast and does not block.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

The only issue is if we are interrupted when getting the return value of timer_ticks. So, we turn off interrupts as we query for the number of ticks since the kernel started, and then turn them off right after.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

We block critical sections of code by disabling interrupts. The critical sections are inside of timer_ticks() where we read the value of ticks. Since timer_sleep() also calls thread_sleep(), we also make sure to turn off interrupts when inserting the current thread into the wait_list.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because it may be important in the future to be able to keep track of all sleeping threads based on their wake-up time. We initially considered not having a list of current sleeping threads and just looping through all threads of all states and updating the sleep metadata that way. That design is worse as it's both inefficient and doesn't allow an easy way to keep track of the order of threads to be woken up.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.c
--------

/* The following methods were declared in thread.h but defined in thread.c */

/* Helper method for both priority scheduler and MLFQS */
int get_priority(struct thread *t); /* get's the priority of the thread based on 
                                       whatever scheduler the system is set to use */

/* Added for Priority Scheduling */

/* compares the priority of two threads; used for ordering */
bool thread_priority_compare (const struct list_elem *a, const struct list_elem *b, void *aux); 

/* performs a priority donation from one thread to another */
void donate_priority(struct thread *source, struct thread *target);

/* This removes priority donations from a thread with respect to a lock*/
void empty_donated_priority(struct thread *t, struct lock *lock);


thread.h
--------

/* This is the maxiumum depth for priority donation. */
#define DONATE_DEPTH 8

/* This represents a priority donation.  */
struct donor_elem {
  struct thread *t;      /* This is the thread that made the donation. */
  int donation;          /* This is the donation that the thread made. */
  struct list_elem elem; /* Used for keeping track of all donors to a thread.*/
};

/* The following were added to struct thread */

/* Stuff for Priority Donation */
int donated_priority;         /* Maintains the highest donated priority to the thread. */
struct list donor_list;       /* Keeps a list of all donations to the thread. */
struct thread *donee;         /* Which thread that this thread has donated to. */
struct lock *waiting_on_lock; /* The lock that this thread is waiting on. */

synch.h
-------

/* added to struct lock */
struct list_elem elem; /* added so that one can maintain a list of locks*/


synch.c
------

/* This method was declared in synch.h but implemented in synch.c */
/* This compared two semaphores in a condvar.  It compares the priorities of the threads that are holding/waiting on the semaphore */
bool sema_priority_compare (const struct list_elem *a, const struct list_elem *b, void *aux);

/* Added to struct semaphore_elem */
/* Needed for condvars */
struct thread *owner; /* In a list of semaphores, this keeps track of which thread added the semaphore to the semaphore list.  This is necessary for sorting the semphores based on the priorities of their owner threads. */


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

In order to make priority donation work, every thread maintains three things:
1) Its priority (priority)
2) The highest priority donated to the thread (donated_priority)
3) A list of all priority donations to the thread.

An entry in the priority donation 

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

in thread.c

static int ready_list_length; //Length of the ready list - for convenient use in the timer interrupt.
static fp_t load_avg; // load average

in thread.h::thread

int nice; // Niceness of a thread.
fp_t recent_cpu; // Recent_cpu value

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

load avg and recent cpu dont change via the formula


priority = 63 - (recent/4) - nice*2
recent up by 1 for running
timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  31  31  31  A
 4      4   0   0  62  61  59  A
 8      8   0   0  61  61  59  B
12      8   4   0  61  60  59  A
16      12  4   0  60  60  59  B
20      12  8   0  60  59  59  A
24      16  8   0  59  59  59  C
28      16  8   4  59  59  58  B
32      16  12  4  59  58  58  A
36      20  12  4  58  58  58  C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

- If priorities are the same to begin, which thread starts? We just use the thread at the beginning of the queue, and it does the same as ours.

- How do we deal with round-robin when dealing with the number of threads having priority X increasing from interrupt to interrupt? We just made sure that when a thread is re-inserted to the ready list, it is pushed to the back of its subset of priorities (so if A, B have PRI 30 and C just went to ready from running, then the queue will be A,B,C, so A runs next (assuming no other threads have PRI > 30)). This matches the behavior of our scheduler.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

- The code to update all of the parameters for MLFQS happen in external interrupt context (during the timer interrupt) so that means they are called every timer interrupt. All other schedule code (donating, etc.) is called from an internal interrupt context so we switch off when needed. By keeping only the logic for updating MLFQS data within the timer interrupt, we increase our performance by not having extra code that isn't as necessary every interrupt.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

A nice advantage is that the design is fairly clean from the priority to MLFQS. We only need to add in the metadata with cpu load, recent cpu, niceness and the structure of our queue and list insert implies things work as desired. A disadvantage is that if we wanted to scale, things wouldn't be as nice because we'd have one gigantic queue - it might be good at that point ot split the giant queue into a few queues with ranges of priority lvels.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We used the library provided. In any case we'd probably have done it in a similar fashion because abstracting out the fixed point math makes life easier when storing data that is persistent through the program (cpu load, recent cpu). Moreover it makes things more readable when you know what is exactly happening with data flow.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

I wouldn't say anything was too easy. The priority donation was a little tedious because of all the list manipulation with C, in addition we overflowed the stack at some points and in other spots placing some code at some points could cause page faults. A bit of mysterious things...took a while to settle on the design. Luckily finishing this made MLFQS pretty straightforward.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

Respect for people who write the schedulers, awareness of the issues with multithreading.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

Tips to avoid stack overflow, more highlighting of dangerous places to put code.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

Not really, good guidance on this one.

>> Any other comments?
